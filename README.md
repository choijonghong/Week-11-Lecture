# Week-11-Lecture
Week-11-Lecture

### VAE는 어떻게 생성형 AI 시대를 열었는가?
* 논문명: Auto-Encoding  Variational Bayes

### 논문배경
* 세상의 모든 데이터에는 눈에 보이지 않는 핵심 특징들이 숨어 있습니다. 우리는 이것을 수학적으로 **잠재 변수(z)라고 부르지만, 쉽게 말해 '설계도' 혹은 '레시피'라고 생각하면 됩니다.
* (예시) 고양이 사진 (x)
       * 눈에 보이는 것: 픽셀 덩어리
       * 숨겨진 설계도 (z): 귀가 뾰족함, 털이 하양, 눈이 동그랗다.
* AI가 이 설계도(z)만 알아낼 수 있다면, 고양이 사진을 단순히 외우는 게 아니라 "귀가 뾰족하고 털이 검은 고양이"를 새로 그려낼 수 있게 됩니다. 


### 기존 연구의 한계점: 장님 코끼리 만지기
* 예전 방식은 이 설계도를 찾는 과정이 너무나 험난했습니다.
* 문제: 설계도를 역추적하는 확률(P(z|x))을 계산하는 것이 수학적으로 거의 불가능할 정도로 복잡했습니다.
* 비유: 수백만 개의 레고 조각(데이터)이 바닥에 흩어져 있는데, 조립 설명서 없이 완성품을 상상하며 다시 조립하려는 것과 같았습니다.
* 결과: 계산하는 데 몇 년이 걸리거나, 아예 불가능했습니다.

### 논문 목표
* 설계도를 빨리 자동으로 찾고 싶다.
* 설계도를 자동으로 찾고, 그 설계도를 사용해 다시 만들어보자

### 논문내용(주요 혁신 및 방법론)
* VAE의 해결책: "인코더와 디코더의 협동 작전"
   * VAE는 이 문제를 해결하기 위해 두 명의 기술자를 고용했습니다.
  
* 인코더 (Encoder): "요약의 달인"
   * 역할: 복잡한 사진(데이터)을 보고 핵심 특징(설계도 $z$)을 추측합니다.
   * 하는 일: "이 사진은 뾰족 귀 80%, 흰 털 20%의 특징을 가졌어!"라고 평균(u)과 범위(시그마)를 요약해줍니다.
* 일반화 성능 향상
   * 지역응답 정규화(LRN)
   * 중첩 풀링(Overlapping Pooling)

### 기여도 및 결과
* 경쟁 우위 확보: ILSVRC-2010 대회에서 기존 최고 기록(Top-5 오류율 28.2%)을 훨씬 능가하는 Top-5 오류율 **17.0%**를 달성.
* 대회 우승: ILSVRC-2012 대회에서도 압도적인 차이(2등 26.2% 대비)로 Top-5 테스트 오류율 15.3%를 기록하며 우승.
* 깊이의 중요성 입증: 단 하나의 컨볼루션 계층만 제거해도 성능이 저하된다는 것을 보여주어, 깊은 네트워크 구조의 중요성 입증.
* 딥러닝의 부활: 대규모 CNN이 순수 지도 학습만으로도 매우 어려운 데이터셋에서 기록적인 결과를 달성할 수 있음을 보여주며, 이후 딥러닝 연구의 폭발적인 성장을 이끎

### CNN & 감성컴퓨팅
* 감성 컴퓨팅은 컴퓨터가 인간의 감정을 인식하고 이해하도록 돕는 분야입니다.
* CNN(합성곱 신경망)은 주로 이미지 분석에 특화된 강력한 딥러닝 모델입니다.
* CNN은 사람의 얼굴 표정 이미지를 분석하여 감정을 나타내는 시각적 특징을 추출합니다.
* 또한, 음성 데이터를 시각화한 스펙트로그램 이미지를 분석하여 목소리의 감정 패턴을 인식할 수도 있습니다.
* 따라서 CNN은 시각 및 청각 데이터를 기반으로 감성 컴퓨팅 모델이 정확하게 감정을 분류할 수 있게 하는 핵심적인 도구입니다.

### 참고 파일

* 논문1. ImageNet Classification with Deep Convolutional Neural Networks
* 코드1. CiFAR-10 분류를 위한 CNN 모델
* 코드해설 1. CiFAR-10 분류를 위한 CNN 모델 해설
* CNN+합성곱 예시. 
